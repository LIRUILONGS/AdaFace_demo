#!/usr/bin/env python
# -*- encoding: utf-8 -*-
"""
@File    :   AdafaceRecognition.py
@Time    :   2023/06/17 22:38:21
@Author  :   Li Ruilong
@Version :   1.0
@Contact :   liruilonger@gmail.com
@Desc    :   FaceCollection äººè„¸æ£€æµ‹è¯»å– æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œå†™å…¥æ•°æ®
"""

# here put the import lib
import net
import torch
import os
import base64
from pathlib import Path
from face_alignment import align
import numpy as np
import pandas as pd
import pickle
import time
import imutils
from imutils import paths
import cv2
import uuid
from os import path
from tqdm import tqdm
from PIL import Image
import requests
import face_yaw_pitc_roll
import hashlib
import glob
import base64
import utils

from redis_uits import RedisClient


class FaceCollection:
    __instance = None
    adaface_models = {
        'ir_101': "pretrained/adaface_ir101_webface12m.ckpt",
    }

    def __new__(cls, *args, **kwargs):
        if cls.__instance is None:
            cls.__instance = super().__new__(cls)
        return cls.__instance

    def __init__(self, face_path, adaface_model_name='adaface_model', architecture='ir_101',face_image='img_dir'):
        """
        @Time    :   2023/06/17 22:41:40
        @Author  :   liruilonger@gmail.com
        @Version :   3.0
        @Desc    :   åˆå§‹åŒ–å¤„ç†ï¼ŒåŠ è½½æ¨¡å‹ï¼Œç‰¹å¾æ–‡ä»¶åŠ è½½
        """
        # ç”Ÿæˆçš„ç‰¹å¾çš„ æ¨¡å‹ Kï¼Œå¯¹åº”æ•°æ®åº“ç‰¹å¾åˆ—è¡¨åç§°
        self.adaface_model_name = adaface_model_name

        # é‡‡é›†çš„çš„æ–‡ä»¶ä½ç½®
        self.face_path = face_path

        # ä½¿ç”¨çš„æ¨¡å‹æ–‡ä»¶
        self.architecture = architecture

        # å­˜æ”¾å›¾ç‰‡çš„ set
        self.face_image = face_image

        # redis
        self.rc = RedisClient()

        self.load_pretrained_model()

    def load_pretrained_model(self):
        """
        @Time    :   2023/06/19 23:50:58
        @Author  :   liruilonger@gmail.com
        @Version :   1.0
        @Desc    :   åŠ è½½æ¨¡å‹
                     Args:
                       
                     Returns:
                       void
        """

        assert self.architecture in self.adaface_models.keys()
        self.model = net.build_model(self.architecture)
        statedict = torch.load(self.adaface_models[self.architecture], map_location=torch.device('cpu'))['state_dict']
        model_statedict = {key[6:]: val for key, val in statedict.items() if key.startswith('model.')}
        self.model.load_state_dict(model_statedict)
        self.model.eval()
        print("ğŸ˜ğŸ˜ŠğŸ˜ğŸ˜ŠğŸ˜ğŸ˜ŠğŸ˜ğŸ˜ŠğŸ˜ğŸ˜Š æ¨¡å‹ åŠ è½½å®Œæˆ")
        return self

    def to_input(self, pil_rgb_image):
        """
        @Time    :   2023/06/17 22:42:30
        @Author  :   liruilonger@gmail.com
        @Version :   1.0
        @Desc    :   è¯†åˆ«å›¾ç‰‡é¢„å¤„ç†
                     Args:
                       
                     Returns:
                       void
        """

        tensor = None
        try:
            np_img = np.array(pil_rgb_image)
            brg_img = ((np_img[:, :, ::-1] / 255.) - 0.5) / 0.5
            # tensor = torch.tensor([brg_img.transpose(2, 0,1)]).float()
            tensor = torch.tensor(np.array([brg_img.transpose(2, 0, 1)])).float()

        except Exception:
            # print("è¯†åˆ«å›¾ç‰‡é¢„å¤„ç†å¼‚å¸¸,å›¾ç‰‡è‡ªåŠ¨å¿½ç•¥")
            pass
        return tensor

    def build_vector_db(self):
        """
        @Time    :   2023/06/19 23:02:16
        @Author  :   liruilonger@gmail.com
        @Version :   1.0
        @Desc    :   æå–äººè„¸ç‰¹å¾åˆ°æ•°æ®åº“
        """

        employees = list(paths.list_images(self.face_path))
        el = len(employees)
        if el == 0:
            raise ValueError("æ²¡æœ‰ä»»ä½•å›¾åƒåœ¨  ", self.face_path, "  æ–‡ä»¶å¤¹! éªŒè¯æ­¤è·¯å¾„ä¸­æ˜¯å¦å­˜åœ¨ .jpg æˆ– .png æ–‡ä»¶ã€‚", )
        pbar = tqdm(
            range(0, el),
            desc="é‡‡é›†å‘é‡ç‰¹å¾æ•°æ®ä¸­ï¼šâš’ï¸âš’ï¸âš’ï¸",
            mininterval=0.1,
            maxinterval=1.0,
            smoothing=0.1,
            colour='green',
            postfix=" âš’ï¸"
        )
        for index in pbar:
            employee = employees[index]
            md5_str = None
            try:
                md5_str = utils.get_file_md5(employee)
            except :
                print(f"è¯»å–æ–‡ä»¶å¤±è´¥{employee}")
                continue
            # å¦‚æœå¤„ç†è¿‡ç›´æ¥è·³å‡ºå»
            if md5_str is not None:
                if self.rc.sismember(self.face_image,md5_str):
                    print(f"å¤„ç†è¿‡çš„å›¾ç‰‡ï¼š{employee}")
                    continue
                else: 
                    self.rc.sadd(self.face_image,md5_str)

            img_representation = self.get_represents(employee)
            if img_representation is not []:
                pbar = tqdm(
                    range(0, len(img_representation)),
                    desc="å•å¼ äººè„¸ç‰¹å¾é‡‡é›†ä¸­ï¼šğŸ”¬ğŸ”¬ ",
                    colour='red',
                    postfix="ğŸ”¬ğŸ”¬")
                for i in pbar:
                    my_tuple  = img_representation[i]
                    self.rc.rpush(self.adaface_model_name, (pickle.dumps(my_tuple)))

        return self

    def get_represents(self, path):
        """
        @Time    :   2023/06/18 06:03:09
        @Author  :   liruilonger@gmail.com
        @Version :   1.0
        @Desc    :   è·å–å¤šä¸ªè„¸éƒ¨ç‰¹å¾å‘é‡
                     Args:
                       
                     Returns:
                       features_t --> [(ç‰¹å¾å‘é‡,äººè„¸ Image.Image)]   è¿”å›ç‰¹å¾å‘é‡å’Œå¯¹åº”äººè„¸ Image.Image å¯¹è±¡ çš„ list
        """
        features_t = []
        try:
            aligned_rgb_imgs = align.get_aligned_face(path)
        except Exception:
            pass
            # print(f"æ— æ³•æå–rgb å›¾åƒ: {path}")
            return features_t
        if aligned_rgb_imgs is not None:
            for aligned_rgb_img in aligned_rgb_imgs:
                bgr_tensor_input = self.to_input(aligned_rgb_img)
                if bgr_tensor_input is not None:
                    with torch.no_grad():
                        feature, _ = self.model(bgr_tensor_input)

                    features_t.append((feature, aligned_rgb_img))
                else:
                    # print(f"æ— æ³•æå–è„¸éƒ¨ç‰¹å¾å‘é‡: {path}")
                    pass
        return features_t








if __name__ == '__main__':
    test_image_path = 'W:\python_code\deepface\\temp\\temp'
    face_c = FaceCollection(face_path=test_image_path, adaface_model_name="adaface_model",face_image="img_dir")
    test_image_path = 'W:\python_code\deepface\\temp\\temp'

    face_c.build_vector_db()
