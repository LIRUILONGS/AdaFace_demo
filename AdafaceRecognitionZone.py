#!/usr/bin/env python
# -*- encoding: utf-8 -*-
"""
@File    :   AdafaceRecognition.py
@Time    :   2023/06/17 22:38:21
@Author  :   Li Ruilong
@Version :   1.0
@Contact :   liruilonger@gmail.com
@Desc    :   Adaface äººè„¸è¯†åˆ« é™Œç”Ÿäººåˆ†åŒºåŸŸå¤„ç†
"""

# here put the import lib
import net
import torch
import os
import base64
from pathlib import Path
from face_alignment import align
import numpy as np
import pandas as pd
import pickle
import time
import imutils 
from imutils import paths
import cv2
import uuid
from os import path
from tqdm import tqdm
from PIL import Image
import requests
import face_yaw_pitc_roll


class AdafaceRecognition:
    __instance = None
    adaface_models = {
        'ir_101': "pretrained/adaface_ir101_webface12m.ckpt",
    }
    



    def __new__(cls, *args, **kwargs):
        if cls.__instance is None:
            cls.__instance = super().__new__(cls)
        return cls.__instance

    def __init__(self, db_path,adaface_model_name='adaface_model',architecture='ir_101'):
        """
        @Time    :   2023/06/17 22:41:40
        @Author  :   liruilonger@gmail.com
        @Version :   1.0
        @Desc    :   åŠ è½½æ¨¡å‹ï¼Œç‰¹å¾æ–‡ä»¶åŠ è½½
                     Args:
                       
                     Returns:
                       void
        """
        # æ¨¡å‹åŠ è½½
        self.adaface_model_name = adaface_model_name
        self.db_path = db_path
        # é™Œç”Ÿäººåˆ†ç±»
        self.features = {}
        self.load_pretrained_model(architecture)
        self.build_vector_pkl(self.db_path,self.adaface_model_name)
        self.read_vector_pkl(self.db_path, self.adaface_model_name)


    def load_pretrained_model(self,architecture='ir_101'):
        assert architecture in self.adaface_models.keys()
        self.model = net.build_model(architecture)
        statedict = torch.load(
            self.adaface_models[architecture], map_location=torch.device('cpu'))['state_dict']
        model_statedict = {key[6:]: val for key,
                           val in statedict.items() if key.startswith('model.')}
        self.model.load_state_dict(model_statedict)
        self.model.eval()
        print("ğŸ˜ğŸ˜ŠğŸ˜ğŸ˜ŠğŸ˜ğŸ˜ŠğŸ˜ğŸ˜ŠğŸ˜ğŸ˜Š model åŠ è½½å®Œæˆ")


    def to_input(self,pil_rgb_image):
        """
        @Time    :   2023/06/17 22:42:30
        @Author  :   liruilonger@gmail.com
        @Version :   1.0
        @Desc    :   è¯†åˆ«å›¾ç‰‡é¢„å¤„ç†
                     Args:
                       
                     Returns:
                       void
        """
        
        tensor = None
        try:
            np_img = np.array(pil_rgb_image)
            brg_img = ((np_img[:, :, ::-1] / 255.) - 0.5) / 0.5
            #tensor = torch.tensor([brg_img.transpose(2, 0,1)]).float()
            tensor = torch.tensor(np.array([brg_img.transpose(2, 0,1)])).float()

        except Exception :
            #print("è¯†åˆ«å›¾ç‰‡é¢„å¤„ç†å¼‚å¸¸,å›¾ç‰‡è‡ªåŠ¨å¿½ç•¥")
            pass    
        return tensor    

    def read_vector_pkl(self,db_path, adaface_model_name):
        """
        @Time    :   2023/06/16 12:10:47
        @Author  :   liruilonger@gmail.com
        @Version :   1.0
        @Desc    :   è¯»å–ç‰¹å¾å‘é‡æ–‡ä»¶
                     Args:

                     Returns:
                       df
        """
        
        file_name = f"representations_adaface_{adaface_model_name}.pkl"
        self.file_name = file_name.replace("-", "_").lower()
        with open(f"{db_path}/{file_name}", "rb") as f:
                representations = pickle.load(f)
        self.df = pd.DataFrame(representations, columns=["identity", f"{adaface_model_name}_representation"])
        print("ğŸ˜ğŸ˜ŠğŸ˜ğŸ˜ŠğŸ˜ğŸ˜ŠğŸ˜ğŸ˜ŠğŸ˜ğŸ˜Š representation  åŠ è½½å®Œæˆ")


    def build_vector_pkl(self,db_path, adaface_model_name='adaface_model'):
        """
        @Time    :   2023/06/16 11:40:23
        @Author  :   liruilonger@gmail.com
        @Version :   1.0
        @Desc    :   æ„å»ºç‰¹å¾å‘é‡æ–‡ä»¶
                     Args:

                     Returns:
                       void
        """
        tic = time.time()

        if os.path.isdir(db_path) is not True:
            raise ValueError("Passed db_path does not exist!")

        file_name = f"representations_adaface_{adaface_model_name}.pkl"
        file_name = file_name.replace("-", "_").lower()
        if path.exists(db_path + "/" + file_name):
            pass
        else:
            employees = []
            for r, _, f in os.walk(db_path):
                for file in f:
                    if (
                        (".jpg" in file.lower())
                        or (".jpeg" in file.lower())
                        or (".png" in file.lower())
                    ):
                        exact_path = r + "/" + file
                        employees.append(exact_path)

            if len(employees) == 0:
                raise ValueError(
                    "æ²¡æœ‰ä»»ä½•å›¾åƒåœ¨  ",
                    db_path,
                    "  æ–‡ä»¶å¤¹! éªŒè¯æ­¤è·¯å¾„ä¸­æ˜¯å¦å­˜åœ¨.jpgæˆ–.pngæ–‡ä»¶ã€‚",
                )
            representations = []

            pbar = tqdm(
                range(0, len(employees)),
                desc="ç”Ÿæˆå‘é‡ç‰¹å¾æ–‡ä»¶ä¸­ï¼šâš’ï¸âš’ï¸âš’ï¸",
                mininterval=0.1, 
                maxinterval=1.0, 
                smoothing=0.1,                 
                colour='green',
                postfix=" âš’ï¸"
            )
            for index in pbar:
                employee = employees[index]

                img_representation = self.get_represent(employee)[0]
                instance = []
                instance.append(employee)
                instance.append(img_representation)
                representations.append(instance)


            with open(f"{db_path}/{file_name}", "wb") as f:
                pickle.dump(representations, f)
            print("ğŸ˜ğŸ˜ŠğŸ˜ğŸ˜ŠğŸ˜ğŸ˜ŠğŸ˜ğŸ˜ŠğŸ˜ğŸ˜Š representations  æ„å»ºå®Œæˆ")    


    def find_face(self,test_image_path,threshold=0.5):
        """
        @Time    :   2023/06/16 14:02:52
        @Author  :   liruilonger@gmail.com
        @Version :   1.0
        @Desc    :   æ ¹æ®å›¾ç‰‡åœ¨äººè„¸åº“æ¯”å¯¹æ‰¾äºº(å•äºº)
                     Args:

                     Returns:
                       void
        """

        test_representation = self.get_represent(test_image_path)
        if test_representation  is  not None:
            reset = {}
            for index, instance in self.df.iterrows():
                source_representation = instance[f"{self.adaface_model_name}_representation"]
                ten = AdafaceRecognition.findCosineDistance(source_representation,test_representation)
                reset[ten.item()]= instance["identity"]        
            cosine_similarity =  max(reset.keys())        
            return cosine_similarity > threshold ,reset[cosine_similarity]
        else:
            return False,0

    def find_faces(self,test_image_path,threshold=0.5):
        """
        @Time    :   2023/06/18 06:16:19
        @Author  :   liruilonger@gmail.com
        @Version :   1.0
        @Desc    :   æ ¹æ®å›¾ç‰‡åœ¨äººè„¸åº“æ¯”å¯¹æ‰¾äºº(å¤šäºº)
                     Args:
                       
                     Returns:
                       è¿”å›æ¯”å¯¹ç»“æœé›†
                        b -->   è¯†åˆ«ç»“æœ              cosine_similarity > threshold 
                        c -->   æ¯”å¯¹å®Œçš„æœ€å¤§ç›¸ä¼¼åº¦å¾—åˆ† cosine_similarity
                        r -->   å¯¹åº”çš„äººè„¸åº“äººè„¸ä½ç½®   reset[cosine_similarity]
                        i -->   æ¯”å¯¹çš„å›¾ç‰‡            img
                        t -->   å¯¹æ¯”å›¾ç‰‡çš„ç‰¹å¾å€¼       test_representation

        """

        test_representations = self.get_represents(test_image_path)
        res = []
        if test_representations  is  not []:
            pbar = tqdm(
                range(0, len(test_representations)),
                desc="äººè„¸æ¯”å¯¹ä¸­ï¼šğŸ”¬ğŸ”¬ ",               
                colour='#f7d8d8',
                postfix="ğŸ”¬ğŸ”¬")
            
            for i in pbar:
                test_representation,img =  test_representations[i]
                reset = {}
                for index, instance in self.df.iterrows():
                    source_representation = instance[f"{self.adaface_model_name}_representation"]
                    ten = AdafaceRecognition.findCosineDistance(source_representation,test_representation)
                    reset[ten.item()]= instance["identity"]        
                    # å¦‚æœå¾—åˆ†å¤§äºé˜ˆå€¼`2*1/5`ä¸ªå•ä½ï¼Œåˆ™æ¯”è¾ƒå®Œæˆï¼Œè·³å‡ºå¾ªç¯
                    if threshold + (2*threshold/5)  < ten:
                        break
                cosine_similarity =  max(reset.keys())
                res.append((cosine_similarity > threshold ,cosine_similarity,reset[cosine_similarity],img,test_representation))         
            return res
        else:
            return res

    def get_represent(self,path):
        """
        @Time    :   2023/06/16 11:54:11
        @Author  :   liruilonger@gmail.com
        @Version :   1.0
        @Desc    :   è·å–å•ä¸ªè„¸éƒ¨ç‰¹å¾å‘é‡
                     Args:
                        path: å¯ä»¥æ˜¯å›¾ç‰‡è·¯å¾„ï¼Œè·å–ç¬¬ä¸€ä¸ªäººè„¸çš„ç‰¹å¾å‘é‡ï¼Œä¹Ÿå¯ä»¥æ˜¯ Image.Image å¯¹è±¡
                     Returns:
                       è¿”å›ç‰¹æ€§å‘é‡
        """

        feature = None
        try:
            if isinstance(path, Image.Image):
               aligned_rgb_img =  path
            else:
                aligned_rgb_img = align.get_aligned_face(path)[0]
        except Exception:
            pass  
            #print(f"æ— æ³•æå–rgb å›¾åƒ: {path}") 
            return  feature
        bgr_tensor_input = self.to_input(aligned_rgb_img)
        if bgr_tensor_input is not None:
            feature, _ = self.model(bgr_tensor_input)
        else:
            #print(f"æ— æ³•æå–è„¸éƒ¨ç‰¹å¾å‘é‡: {path}")  
            pass 
        return feature
    

    def get_represents(self,path):
        """
        @Time    :   2023/06/18 06:03:09
        @Author  :   liruilonger@gmail.com
        @Version :   1.0
        @Desc    :   è·å–å¤šä¸ªè„¸éƒ¨ç‰¹å¾å‘é‡
                     Args:
                       
                     Returns:
                       è¿”å›ç‰¹å¾å‘é‡å’Œå¯¹åº”äººè„¸ Image.Image å¯¹è±¡ çš„ list
        """
        features_t = []
        try:
            aligned_rgb_imgs = align.get_aligned_face(path)
        except Exception:
            pass  
            #print(f"æ— æ³•æå–rgb å›¾åƒ: {path}") 
            return  features_t
        if aligned_rgb_imgs is not None:
            for aligned_rgb_img in aligned_rgb_imgs:
                bgr_tensor_input = self.to_input(aligned_rgb_img)
                if bgr_tensor_input is not None:
                    feature, _ = self.model(bgr_tensor_input)
                    features_t.append((feature,aligned_rgb_img))
                else:
                    #print(f"æ— æ³•æå–è„¸éƒ¨ç‰¹å¾å‘é‡: {path}")  
                    pass 
        return features_t
    

    
    @staticmethod
    def marge(m1,m2,path):
        """
        @Time    :   2023/06/17 23:00:32
        @Author  :   liruilonger@gmail.com
        @Version :   1.0
        @Desc    :   å›¾ç‰‡åˆå¹¶
                     Args:

                     Returns:
                       void
        """
        if isinstance(m1, Image.Image):
            image1 = m1
        else:
            image1 = Image.open(m1)

        if isinstance(m2, Image.Image):
            image2 = m2
        else:
            image2 = Image.open(m2)
        
        # è·å–ç¬¬ä¸€å¼ å›¾ç‰‡çš„å¤§å°
        width1, height1 = image1.size
        # è·å–ç¬¬äºŒå¼ å›¾ç‰‡çš„å¤§å°
        width2, height2 = image2.size
        # åˆ›å»ºä¸€ä¸ªæ–°çš„ç”»å¸ƒï¼Œå¤§å°ä¸ºä¸¤å¼ å›¾ç‰‡çš„å®½åº¦ä¹‹å’Œå’Œé«˜åº¦çš„æœ€å¤§å€¼
        new_image = Image.new("RGB", (width1 + width2, max(height1, height2)))
        # å°†ç¬¬ä¸€å¼ å›¾ç‰‡ç²˜è´´åˆ°ç”»å¸ƒçš„å·¦ä¾§
        new_image.paste(image1, (0, 0))
        # å°†ç¬¬äºŒå¼ å›¾ç‰‡ç²˜è´´åˆ°ç”»å¸ƒçš„å³ä¾§
        new_image.paste(image2, (width1, 0))
        # ä¿å­˜æ‹¼æ¥åçš„å›¾ç‰‡
        
        new_image.save(path+os.path.basename(m1))    

    @staticmethod
    def findCosineDistance(source_representation, test_representation):
        """
        @Time    :   2023/06/16 12:19:27
        @Author  :   liruilonger@gmail.com
        @Version :   1.0
        @Desc    :   è®¡ç®—ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦å¾—åˆ†
                     Args:

                     Returns:
                       void
        """
        import torch.nn.functional as F
        return F.cosine_similarity(source_representation, test_representation)
    
    @staticmethod
    def load_image(img):
        exact_image = False
        base64_img = False
        url_img = False

        if type(img).__module__ == np.__name__:
            exact_image = True

        elif img.startswith("data:image/"):
            base64_img = True

        elif img.startswith("http"):
            url_img = True

        # ---------------------------

        if base64_img is True:
            img = AdafaceRecognition.loadBase64Img(img)

        elif url_img is True:
            img = np.array(Image.open(requests.get(img, stream=True, timeout=60).raw).convert("RGB"))

        elif exact_image is not True:  # image path passed as input
            if os.path.isfile(img) is not True:
                raise ValueError(f"Confirm that {img} exists")

            img = cv2.imread(img)

        return img
        
    @staticmethod
    def loadBase64Img(uri):
        encoded_data = uri.split(",")[1]
        nparr = np.fromstring(base64.b64decode(encoded_data), np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        return img  

    
              
    def stranger_weight_removals(self,image,threshold=0.15):
        """
        @Time    :   2023/06/19 02:23:08
        @Author  :   liruilonger@gmail.com
        @Version :   1.0
        @Desc    :   é™Œç”Ÿäººå»é‡
                     Args:
                       image: å»é‡çš„imageï¼Œå¯ä»¥æ˜¯ä¸€ä¸ªå›¾ç‰‡è·¯å¾„ï¼Œä¹Ÿå¯ä»¥æ˜¯ å¤„ç†å®Œçš„ç‰¹å¾å‘é‡ï¼Œ
                     Returns:
                       void
        """
         

        # å›¾ç‰‡ç‰¹å¾å¤„ç†    
        if  isinstance(image, str):
            test_representation = self.get_represents(image)
        else:
            test_representation = image

        if test_representation  is  not None :
            # ç¡®è®¤é™Œç”ŸäººåŒºåŸŸ
            ip_zone = self.ip_zone
            temp_feat = []

            if  ip_zone not in  self.features:
                self.features[ip_zone] = temp_feat
            else :
                temp_feat =  self.features[ip_zone]

            reset = {}
            if  not temp_feat :
                temp_feat.append(test_representation)
                return False, 0
            else:
                pbar = tqdm(
                    range(0, len(temp_feat)),
                    desc="é™Œç”Ÿäººå½’ç±»ï¼šğŸ‘½ğŸ‘½ğŸ‘½ ",
                    mininterval=0.1, 
                    maxinterval=1.0, 
                    smoothing=0.01,                 
                    colour='#f6b26b',
                    postfix="ğŸ‘½ğŸ‘½")
                
                for i in pbar:
                    instance = temp_feat[i]
                    ten = AdafaceRecognition.findCosineDistance(instance,test_representation)
                    reset[ten.item()]= instance 
                    # å¦‚æœå¾—åˆ†å¤§äºé˜ˆå€¼`2*1/5`ä¸ªå•ä½ï¼Œåˆ™æ¯”è¾ƒå®Œæˆï¼Œè·³å‡ºå¾ªç¯
                    if threshold + (2*threshold/5)  < ten:
                        break
                      
                cosine_similarity =  max(reset.keys())      
                if cosine_similarity >= threshold :
                    return True, cosine_similarity   
                else:
                    temp_feat.append(test_representation)
                    return False, cosine_similarity 
                
            self.features[ip_zone] = temp_feat    
                
        else:
            return False,-1
    
    
    def exec(self,img,threshold=0.5):
        return self.find_face(img,threshold)
    
    
    @staticmethod
    def single_re(ada,test_image_path):
        """
        @Time    :   2023/06/18 06:18:56
        @Author  :   liruilonger@gmail.com
        @Version :   1.0
        @Desc    :   å•äººè¯†åˆ«
                     Args:
                       
                     Returns:
                       void
        """
        
        f = set()
        while True:
            print("ğŸ‘»ğŸ‘»ğŸ‘»ğŸ‘»ğŸ§Ÿâ€â™€ï¸ğŸ§Ÿâ€â™€ï¸ğŸ§Ÿâ€â™€ï¸ğŸ§Ÿâ€â™€ï¸ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ¥¶ğŸ˜¡ğŸ¤¢ğŸ˜ˆğŸ‘½ğŸ˜¹ğŸ™ˆğŸ¦",time.time())
            file_paths = list(paths.list_images(test_image_path))
            pbar = tqdm(
                    range(0, len(file_paths)),
                    desc="äººè„¸è¯†åˆ«ä¸­ï¼šğŸ‘» ",
                    mininterval=0.1, 
                    maxinterval=1.0, 
                    smoothing=0.01,                 
                    colour='#b6d7a8',
                    postfix=" ğŸ‘»") 

            for index in pbar:
                    path = file_paths[index]               
                    b, r = ada.find_face(path,0.25)
                    if b:
                        if    r not in f:
                            f.add(r)
                            AdafaceRecognition.marge(r,path,"./")
                    else:
                        img = cv2.imread(path)
                        boo, img = face_yaw_pitc_roll.is_gesture(img,10)
                        if boo:
                            bo,tt  = ada.stranger_weight_removals(path,0.17)
                            if bo:
                                os.remove(path) 
                                continue
                            else:
                                cv2.imwrite(str(tt) +".jpg", img)    
                    os.remove(path) 
            time.sleep(1)        

    def load_memory_db(self):
        """
        @Time    :   2023/06/18 23:21:52
        @Author  :   liruilonger@gmail.com
        @Version :   1.0
        @Desc    :   åŠ è½½å†…å­˜ä¸­å­˜åœ¨çš„è¯†åˆ«æ•°æ®
                     Args:
                       
                     Returns:
                       void
        """
        m_db_f  = f"{self.db_path}/M_{self.file_name}"
        if path.exists(m_db_f):
            pass
            with open(m_db_f, "rb") as f:
                representations = pickle.load(f)
            
        else:
            print("å†…å­˜ç‰¹å¾æ–‡ä»¶æœªä¿å­˜!")


    def save_memory_db(self):
        """
        @Time    :   2023/06/18 23:37:37
        @Author  :   liruilonger@gmail.com
        @Version :   1.0
        @Desc    :   ä¿å­˜å†…å­˜ä¸­å­˜åœ¨çš„è¯†åˆ«æ•°æ®
                     Args:
                       
                     Returns:
                       void
        """
        m_db_f  = f"{self.db_path}/M_{self.file_name}"
        if path.exists(m_db_f):
            
            os.remove(m_db_f)
            self.features 

        else:
            print("å†…å­˜ç‰¹å¾æ–‡ä»¶æœªä¿å­˜!")
            pass
            with open(m_db_f, "rb") as f:
                representations = pickle.load(f)


                




        


    @staticmethod
    def multiplayer_re(ada,test_image_path,is_memory_db=False):
        """
        @Time    :   2023/06/18 06:19:17
        @Author  :   liruilonger@gmail.com
        @Version :   1.0
        @Desc    :   å¤šäººè¯†åˆ«
                     Args:
                       
                     Returns:
                       void
        """
    
        # è¯†åˆ«å‡ºçš„äººè„¸æ•°æ® 
        faces ={}
        fal = True
        while fal:
            
            print("ğŸ‘»ğŸ‘»ğŸ‘»ğŸ‘»ğŸ§Ÿâ€â™€ï¸ğŸ§Ÿâ€â™€ï¸ğŸ§Ÿâ€â™€ï¸ğŸ§Ÿâ€â™€ï¸ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ¥¶ğŸ˜¡ğŸ¤¢ğŸ˜ˆğŸ‘½ğŸ˜¹ğŸ™ˆğŸ¦",time.time())
            file_paths = list(paths.list_images(test_image_path))
            pbar = tqdm(
                    range(0, len(file_paths)),
                    desc="äººè„¸è¯†åˆ«ä¸­ï¼šğŸ‘» ",
                    mininterval=0.1, 
                    maxinterval=1.0, 
                    smoothing=0.01,                 
                    colour='#00ff00',
                    postfix=" ğŸ‘»") 

            for index in pbar:
                    path = file_paths[index]
                    # æ ¹æ®IPåˆ’åˆ†åŒºåŸŸï¼Œåˆ†åŒºåŸŸå¤„ç†
                    ip_zone =  os.path.basename(path).split("_")[0]
                    print("ip_zoneï¼š",ip_zone)
                    ada.ip_zone = ip_zone
                    # 0.18               
                    data_f_r = ada.find_faces(path,0.25)
                    pbar = tqdm(
                        range(0, len(data_f_r)),
                        desc="è¯†åˆ«ç»“æœå½’ç±»ï¼šğŸ‘½ğŸ‘½ğŸ‘½ ",
                        mininterval=0.1, 
                        maxinterval=1.0, 
                        smoothing=0.01,                 
                        colour='#f6b26b',
                        postfix="ğŸ‘½ğŸ‘½")
                    for  index  in   pbar:
                        b,c,r,i,t = data_f_r[index]
                        # è¯†åˆ«æˆåŠŸ
                        if b:
                            if r not in faces:
                                faces[r]=c
                                AdafaceRecognition.marge(r,i,"./")
                            else:
                                if faces[r] < c: 
                                    AdafaceRecognition.marge(r,i,"./")    
                        else:
                            numpy_image = np.array(i)
                            cv2_image = cv2.cvtColor(numpy_image, cv2.COLOR_RGB2BGR)
                            boo, img = face_yaw_pitc_roll.is_gesture(cv2_image,10)
                            if boo:
                                # 0.15
                                bo,tt  = ada.stranger_weight_removals(t,0.2)
                                if bo:
                                    continue
                                else:
                                    cv2.imwrite(str(tt) +".jpg", cv2_image)    
                    os.remove(path) 
            time.sleep(1)
            fal = False
        
if __name__ == '__main__':


    ada =  AdafaceRecognition(db_path="face_alignment/test",adaface_model_name="adaface_model")
    test_image_path = 'W:\python_code\deepface\\temp\\temp'

    #AdafaceRecognition.single_re(ada,test_image_path)
    AdafaceRecognition.multiplayer_re(ada,test_image_path)
    for k in ada.features.keys():
        
        print(f"é™Œç”ŸäººåŒºåŸŸï¼š{k}","é™Œç”Ÿäººä¸ªæ•°:" ,len(ada.features[k]))
    
    
               
        



    

