#!/usr/bin/env python
# -*- encoding: utf-8 -*-
"""
@File    :   AdafaceFaceCollection.py
@Time    :   2023/06/28 04:27:44
@Author  :   Li Ruilong
@Version :   1.0
@Contact :   liruilonger@gmail.com
@Desc    :   AdafaceFaceCollection äººè„¸æ£€æµ‹è¯»å–æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œå†™å…¥æ•°æ®åº“
"""


# here put the import lib
import net
import torch
import os
import base64
from pathlib import Path
from face_alignment import align
import numpy as np
import pandas as pd
import pickle
import time
import imutils
from imutils import paths
import cv2
import uuid
from os import path
from tqdm import tqdm
from PIL import Image
import hashlib
import glob
import base64
import utils
import multiprocessing
import concurrent.futures
import logging
import functools
from concurrent.futures import ThreadPoolExecutor
from redis_uits import RedisClient
import threading



logging.basicConfig(level=logging.DEBUG)

class AdafaceFaceCollection:
    __instance = None
    adaface_models = {
        'ir_101': "pretrained/adaface_ir101_webface12m.ckpt",
    }

    def __new__(cls, *args, **kwargs):
        if cls.__instance is None:
            cls.__instance = super().__new__(cls)
        return cls.__instance

    def __init__(self, face_path, adaface_model_name='adaface_model', architecture='ir_101', face_image='img_dir'):
        """
        @Time    :   2023/06/17 22:41:40
        @Author  :   liruilonger@gmail.com
        @Version :   3.0
        @Desc    :   åˆå§‹åŒ–å¤„ç†ï¼ŒåŠ è½½æ¨¡å‹ï¼Œç‰¹å¾æ–‡ä»¶åŠ è½½
        """
        # ç”Ÿæˆçš„ç‰¹å¾çš„ æ¨¡å‹ Kï¼Œå¯¹åº”æ•°æ®åº“ç‰¹å¾åˆ—è¡¨åç§°
        self.adaface_model_name = adaface_model_name

        # é‡‡é›†çš„çš„æ–‡ä»¶ä½ç½®
        self.face_path = face_path

        # ä½¿ç”¨çš„æ¨¡å‹æ–‡ä»¶
        self.architecture = architecture

        # å­˜æ”¾å›¾ç‰‡çš„ set
        self.face_image = face_image

        # redis
        self.rc = RedisClient()

        self.load_pretrained_model()

    def load_pretrained_model(self):
        """
        @Time    :   2023/06/19 23:50:58
        @Author  :   liruilonger@gmail.com
        @Version :   1.0
        @Desc    :   åŠ è½½æ¨¡å‹
                     Args:
                       
                     Returns:
                       void
        """

        assert self.architecture in self.adaface_models.keys()
        self.model = net.build_model(self.architecture)
        statedict = torch.load(self.adaface_models[self.architecture], map_location=torch.device('cpu'))['state_dict']
        model_statedict = {key[6:]: val for key, val in statedict.items() if key.startswith('model.')}
        self.model.load_state_dict(model_statedict)
        self.model.eval()
        print("ğŸ˜ğŸ˜ŠğŸ˜ğŸ˜ŠğŸ˜ğŸ˜ŠğŸ˜ğŸ˜ŠğŸ˜ğŸ˜Š æ¨¡å‹ åŠ è½½å®Œæˆ")
        return self


def to_input(self, pil_rgb_image):
    """
    @Time    :   2023/06/17 22:42:30
    @Author  :   liruilonger@gmail.com
    @Version :   1.0
    @Desc    :   è¯†åˆ«å›¾ç‰‡é¢„å¤„ç†
                 Args:
                   
                 Returns:
                   void
    """
    tensor = None
    try:
        np_img = np.array(pil_rgb_image)
        brg_img = ((np_img[:, :, ::-1] / 255.) - 0.5) / 0.5
        # tensor = torch.tensor([brg_img.transpose(2, 0,1)]).float()
        tensor = torch.tensor(np.array([brg_img.transpose(2, 0, 1)])).float()
    except Exception:
        # print("è¯†åˆ«å›¾ç‰‡é¢„å¤„ç†å¼‚å¸¸,å›¾ç‰‡è‡ªåŠ¨å¿½ç•¥")
        pass
    return tensor


def build_vector_db(self):
    """
    @Time    :   2023/06/19 23:02:16
    @Author  :   liruilonger@gmail.com
    @Version :   1.0
    @Desc    :   æå–äººè„¸ç‰¹å¾åˆ°æ•°æ®åº“
    """
    employees = list(paths.list_images(self.face_path))
    # æ ¹æ®CPU æ ¸æ•°å¯¹æ–‡ä»¶åˆ—è¡¨åšå¤„ç†
    cpu_count = multiprocessing.cpu_count()
    print(cpu_count,len(employees) )
    # è¿™é‡Œçš„ 4 ä¸º å•ä¸ªè¿›ç¨‹éœ€è¦çš„æ ¸æ•°
    ps = cpu_count// 3
    chunk_size = len(employees) // ps
    print(chunk_size) 
    image_chunks = [employees[i:i+chunk_size] for i in range(0, len(employees), chunk_size)]
    temp_employees = []
    for i in range(len(image_chunks)):
      flattened_list = [item for sublist in image_chunks[i:] +image_chunks[:i] for item in sublist]
      temp_employees.append((self,flattened_list)) 
       
    

    with ThreadPoolExecutor(max_workers=ps,thread_name_prefix="face_thread_") as executor:
        futures = [executor.submit(face_detector, *params) for params in temp_employees]
        results = [future.result() for future in futures]
        print(futures)


def face_detector(self,employees):
        """
        @Time    :   2023/06/28 05:48:12
        @Author  :   liruilonger@gmail.com
        @Version :   1.0
        @Desc    :   æ ¹æ®æ–‡ä»¶åˆ—è¡¨è¿›è¡Œäººè„¸æ£€æµ‹
                     Args:
                       äººè„¸åˆ—è¡¨
                     Returns:
                       void
        """

        el = len(employees)
        if el == 0:
            raise ValueError("æ²¡æœ‰ä»»ä½•å›¾åƒåœ¨  ", self.face_path, "  æ–‡ä»¶å¤¹! éªŒè¯æ­¤è·¯å¾„ä¸­æ˜¯å¦å­˜åœ¨ .jpg æˆ– .png æ–‡ä»¶ã€‚")
        pbar = tqdm(
            range(0, el),
            desc="é‡‡é›†ç‰¹å¾ä¸­: "+ threading.current_thread().name +"ï¼šâš’ï¸âš’ï¸âš’ï¸",
            mininterval=0.1,
            maxinterval=1.0,
            smoothing=0.1,
            colour='green',
            postfix=" âš’ï¸"
        )
        for index in pbar:
            employee = employees[index]
            md5_str = None
            try:
                md5_str = utils.get_file_md5(employee)
            except:
                print(f"è¯»å–æ–‡ä»¶å¤±è´¥{employee}")
                continue
            # å¦‚æœå¤„ç†è¿‡ç›´æ¥è·³å‡ºå»
            if md5_str is not None:
                if self.rc.sismember(self.face_image, md5_str):
                    print(f"å¤„ç†è¿‡çš„å›¾ç‰‡ï¼š{employee}")
                    continue
                else:
                    self.rc.sadd(self.face_image, md5_str)

            img_representation = get_represents(self,employee)
            if img_representation is not []:
                pbar = tqdm(
                    range(0, len(img_representation)),
                    desc="å•å¼ äººè„¸é‡‡é›†ä¸­ï¼šğŸ”¬ğŸ”¬ ",
                    colour='red',
                    postfix="ğŸ”¬ğŸ”¬")
                for i in pbar:
                    my_tuple = img_representation[i]
                    self.rc.rpush(self.adaface_model_name, (pickle.dumps(my_tuple)))

        return self

def get_represents(self, path):
        """
        @Time    :   2023/06/18 06:03:09
        @Author  :   liruilonger@gmail.com
        @Version :   1.0
        @Desc    :   è·å–å¤šä¸ªè„¸éƒ¨ç‰¹å¾å‘é‡
                     Args:
                       
                     Returns:
                       features_t --> [(ç‰¹å¾å‘é‡,äººè„¸ Image.Image)]   è¿”å›ç‰¹å¾å‘é‡å’Œå¯¹åº”äººè„¸ Image.Image å¯¹è±¡ çš„ list
        """
        features_t = []
        try:
            aligned_rgb_imgs = align.get_aligned_face(path)
        except Exception:
            pass
            # print(f"æ— æ³•æå–rgb å›¾åƒ: {path}")
            return features_t
        if aligned_rgb_imgs is not None:
            for aligned_rgb_img in aligned_rgb_imgs:
                bgr_tensor_input = to_input(self,aligned_rgb_img)
                if bgr_tensor_input is not None:
                    with torch.no_grad():
                        feature, _ = self.model(bgr_tensor_input)

                    features_t.append((feature, aligned_rgb_img))
                else:
                    # print(f"æ— æ³•æå–è„¸éƒ¨ç‰¹å¾å‘é‡: {path}")
                    pass
        return features_t
    

def face_detector_warpper(cls_instance, employees):
    print("face_detector_warpper")
    return cls_instance.face_detector(employees)
 

if __name__ == '__main__':
    test_image_path = 'W:\python_code\deepface\\temp\\temp'
    face_c = AdafaceFaceCollection(face_path=test_image_path, adaface_model_name="adaface_model", face_image="img_dir")
    test_image_path = 'W:\python_code\deepface\\temp\\temp'

    build_vector_db(face_c)
    #face_c.test()
